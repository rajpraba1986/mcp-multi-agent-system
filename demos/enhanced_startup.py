#!/usr/bin/env python3
"""
Enhanced MCP Multi-Agent System Startup Script
==============================================

This script starts all agents in the correct order:
1. MCP Hub (Port 5000)
2. PostgreSQL Database Agent (Port 8002) 
3. Enhanced Email Agent (Port 8003)
4. Real Web Extraction Agent (Port 8001)
5. Runs extraction workflow with email notifications

Usage:
python enhanced_startup.py
"""

import asyncio
import os
import sys
import time
import subprocess
import signal
import yaml
from pathlib import Path
from typing import List, Optional, Dict, Any

# Setup path - adjust for new location in launchers/
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))

# Load environment
from dotenv import load_dotenv
load_dotenv()

class EnhancedMCPSystemManager:
    """Manager for the enhanced MCP multi-agent system with email notifications"""
    
    def __init__(self):
        self.processes: List[subprocess.Popen] = []
        self.project_root = project_root
        self.scraping_config = self._load_scraping_config()
        
    def _load_scraping_config(self) -> Dict[str, Any]:
        """Load scraping configuration from YAML file."""
        config_path = self.project_root / "config" / "scraping_config.yaml"
        try:
            with open(config_path, 'r') as file:
                config = yaml.safe_load(file)
                print(f"‚úÖ Loaded scraping configuration: {len(config.get('urls_to_scrape', []))} URLs")
                return config
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to load scraping config: {e}")
            return {"urls_to_scrape": [], "email_settings": {}, "database_settings": {}}
        
    def start_agent(self, script_name: str, agent_name: str, wait_time: int = 3) -> bool:
        """Start an agent script"""
        try:
            script_path = self.project_root / script_name
            if not script_path.exists():
                print(f"‚ùå Script not found: {script_path}")
                return False
                
            print(f"üöÄ Starting {agent_name}...")
            process = subprocess.Popen(
                [sys.executable, str(script_path)],
                cwd=str(self.project_root),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            if process.poll() is None:
                self.processes.append(process)
                print(f"‚è≥ Waiting {wait_time} seconds for {agent_name} to initialize...")
                time.sleep(wait_time)
                
                # Check if still running
                if process.poll() is None:
                    print(f"‚úÖ {agent_name} started successfully")
                    return True
                else:
                    print(f"‚ùå {agent_name} failed to start")
                    return False
            else:
                print(f"‚ùå {agent_name} failed to start immediately")
                return False
                
        except FileNotFoundError:
            print(f"‚ùå Python executable not found")
            return False
        except Exception as e:
            print(f"‚ùå Failed to start {agent_name}: {e}")
            return False
            
    def cleanup(self):
        """Clean up all processes"""
        print("üßπ Cleaning up processes...")
        for process in self.processes:
            try:
                if process.poll() is None:
                    process.terminate()
                    time.sleep(1)
                    if process.poll() is None:
                        process.kill()
            except Exception as e:
                print(f"‚ö†Ô∏è Error cleaning up process: {e}")
        self.processes.clear()

    async def run_enhanced_system(self):
        """Run the complete enhanced system with email notifications"""
        try:
            print("üåü Enhanced MCP Multi-Agent System with Email Notifications")
            print("=" * 80)
            
            # Check environment
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if api_key:
                print(f"‚úÖ ANTHROPIC_API_KEY loaded ({len(api_key)} chars)")
            else:
                print("‚ùå ANTHROPIC_API_KEY not found!")
                return
            
            # Start agents in order
            if not self.start_agent("src/hub/mcp_hub.py", "MCP Hub", 5):
                print("‚ùå Failed to start MCP Hub")
                return
                
            if not self.start_agent("src/agents/postgresql_database_agent.py", "PostgreSQL Database Agent", 8):
                print("‚ùå Failed to start Database Agent")
                return
                
            if not self.start_agent("src/agents/real_email_agent.py", "Real Email Agent", 5):
                print("‚ùå Failed to start Email Agent")
                return
                
            if not self.start_agent("launchers/browserbase_server.py", "Browserbase MCP Server", 5):
                print("‚ùå Failed to start Browserbase MCP Server")
                return
                
            print("\n" + "=" * 80)
            print("üéâ ALL AGENTS STARTED SUCCESSFULLY!")
            print("=" * 80)
            print("üìä System Status:")
            print("   ‚Ä¢ MCP Hub: ‚úÖ Running on port 5000")
            print("   ‚Ä¢ Database Agent: ‚úÖ Running on port 8002")
            print("   ‚Ä¢ Email Agent: ‚úÖ Running on port 8003")
            print("   ‚Ä¢ Browserbase MCP Server: ‚úÖ Running on port 8001")
            print(f"   ‚Ä¢ Email recipient: {os.getenv('EMAIL_RECIPIENT', 'Not configured')}")
            print("=" * 80)
            
            # Wait for initialization
            print("‚è≥ Waiting for full system initialization...")
            await asyncio.sleep(5)
            
            print("\nüöÄ Running configured URL extraction workflow with email notifications...")
            print("=" * 80)
            
            # Run configured URL extraction workflow using browserbase MCP server
            try:
                # Import the simple MCP client and email client
                import sys
                sys.path.append(str(self.project_root / "src" / "client"))
                from simple_mcp_client import MCPClient
                from email_client import EmailAgentClient
                
                # Get URLs from scraping configuration
                urls_to_scrape = self.scraping_config.get('urls_to_scrape', [])
                active_urls = [url_config for url_config in urls_to_scrape if url_config.get('active', True)]
                
                if not active_urls:
                    print("‚ö†Ô∏è  No active URLs found in scraping configuration")
                    return
                
                print(f"üìã Processing {len(active_urls)} configured URLs...")
                
                extraction_results = []
                successful_extractions = 0
                failed_extractions = 0
                
                # Process each configured URL
                for url_config in active_urls:
                    url = url_config['url']
                    name = url_config['name']
                    extraction_type = url_config.get('extraction_type', 'general')
                    description = url_config.get('description', '')
                    
                    print(f"\nüåê Extracting: {name}")
                    print(f"   URL: {url}")
                    print(f"   Type: {extraction_type}")
                    
                    try:
                        # 1. Web Extraction via Browserbase MCP Server
                        async with MCPClient("http://localhost:8001") as browserbase_client:
                            # Test connection first
                            connection_test = await browserbase_client.test_connection()
                            if not connection_test:
                                raise Exception("Cannot connect to browserbase server")
                            
                            # Configure extraction parameters based on URL config
                            extraction_params = {
                                "url": url,
                                "extraction_type": extraction_type,
                                "include_links": True,
                                "max_pages": url_config.get('max_pages', 1)
                            }
                            
                            # Add specific selectors for different extraction types
                            if extraction_type == "news":
                                extraction_params["selectors"] = {
                                    "title": "a.titlelink, .title a, h1, h2",
                                    "content": ".content, article, .story-text",
                                    "links": "a[href]"
                                }
                            elif "stock" in url.lower() or "finance" in url.lower():
                                extraction_params["selectors"] = {
                                    "price": "[data-symbol], .Trsdu\\(0\\.3s\\), .Fw\\(b\\).Fz\\(36px\\)",
                                    "change": "[data-reactid] span[dir='ltr'], .Fw\\(500\\)",
                                    "stats": "table tr, .Bd\\(t\\) tr"
                                }
                            
                            web_response = await browserbase_client.call_tool(
                                "extract_website_data",
                                extraction_params
                            )
                            
                            if web_response and web_response.get("status") == "success":
                                extraction_result = {
                                    "url": url,
                                    "name": name,
                                    "title": web_response.get("title", name),
                                    "content": web_response.get("content", ""),
                                    "links": web_response.get("links", []),
                                    "extracted_data": web_response.get("data", {}),
                                    "status": "success",
                                    "extraction_type": extraction_type,
                                    "description": description,
                                    "timestamp": time.time()
                                }
                                
                                print(f"   ‚úÖ Extraction successful")
                                successful_extractions += 1
                                
                            else:
                                # Create fallback data for testing
                                extraction_result = {
                                    "url": url,
                                    "name": name,
                                    "title": name,
                                    "content": f"Fallback content for {name} - {description}",
                                    "links": [url],
                                    "extracted_data": {
                                        "source": "fallback",
                                        "extraction_type": extraction_type,
                                        "reason": "browserbase_unavailable"
                                    },
                                    "status": "fallback",
                                    "extraction_type": extraction_type,
                                    "description": description,
                                    "timestamp": time.time()
                                }
                                print(f"   ‚ö†Ô∏è  Using fallback data")
                                successful_extractions += 1
                                
                    except Exception as e:
                        print(f"   ‚ùå Extraction failed: {str(e)[:50]}...")
                        failed_extractions += 1
                        
                        # Create error record
                        extraction_result = {
                            "url": url,
                            "name": name,
                            "title": f"Failed: {name}",
                            "content": f"Extraction failed: {str(e)}",
                            "links": [],
                            "extracted_data": {"error": str(e)},
                            "status": "failed",
                            "extraction_type": extraction_type,
                            "description": description,
                            "timestamp": time.time()
                        }
                    
                    extraction_results.append(extraction_result)
                
                print(f"\nüìä Extraction Summary:")
                print(f"   ‚Ä¢ Successful: {successful_extractions}")
                print(f"   ‚Ä¢ Failed: {failed_extractions}")
                print(f"   ‚Ä¢ Total: {len(extraction_results)}")
                
                # 2. Database Storage for all extractions
                database_success = 0
                database_failed = 0
                
                print(f"\nüíæ Storing {len(extraction_results)} extractions in database...")
                
                for result in extraction_results:
                    try:
                        async with MCPClient("http://localhost:8002") as db_client:
                            storage_response = await db_client.call_tool(
                                "store_extraction",
                                {
                                    "url": result["url"],
                                    "title": result["title"],
                                    "content": result["content"],
                                    "extraction_type": result["extraction_type"],
                                    "structured_data": str(result["extracted_data"])
                                }
                            )
                            
                            if storage_response:
                                result["database_result"] = {"status": "success"}
                                database_success += 1
                            else:
                                result["database_result"] = {"status": "failed"}
                                database_failed += 1
                                
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  Database error for {result['name']}: {str(e)[:30]}...")
                        result["database_result"] = {"status": "failed", "error": str(e)}
                        database_failed += 1
                
                print(f"   ‚úÖ Database storage: {database_success} success, {database_failed} failed")
                
                # 3. Email Notification with all extraction results
                print(f"\nüìß Sending batch email notification...")
                
                try:
                    async with EmailAgentClient("http://localhost:8003") as email_client:
                        email_response = await email_client.send_extraction_notification(
                            extracted_data=extraction_results,
                            total_extractions=len(extraction_results),
                            extraction_summary=f"Batch extraction completed: {successful_extractions} successful, {failed_extractions} failed from {len(active_urls)} configured URLs"
                        )
                        
                        if email_response and email_response.get("status") == "success":
                            print(f"   ‚úÖ Email notification sent successfully")
                            email_result = {
                                "status": "success", 
                                "subject": email_response.get("subject", ""),
                                "recipient": email_response.get("recipient", "")
                            }
                        else:
                            print(f"   ‚ö†Ô∏è  Email notification issues") 
                            email_result = {"status": "failed"}
                            
                except Exception as e:
                    print(f"   ‚ùå Email notification error: {str(e)[:50]}...")
                    email_result = {"status": "failed", "error": str(e)}
                
                # Compile final results
                workflow_result = {
                    "extracted_data": extraction_results,
                    "total_extractions": len(extraction_results),
                    "successful_extractions": successful_extractions,
                    "failed_extractions": failed_extractions,
                    "database_success": database_success,
                    "database_failed": database_failed,
                    "email_result": email_result,
                    "status": "success" if successful_extractions > 0 else "failed"
                }
                        
            except Exception as e:
                print(f"‚ùå Workflow error: {e}")
                workflow_result = {
                    "error": str(e),
                    "extracted_data": [],
                    "status": "failed"
                }
            
            result = workflow_result
            
            print("\n" + "=" * 80)
            print("üéØ COMPLETE WORKFLOW RESULTS")
            print("=" * 80)
            
            if result.get("status") == "success" and result.get("extracted_data"):
                print("‚úÖ Complete workflow executed successfully!")
                print(f"üìä Total extractions: {result.get('total_extractions', 0)}")
                print(f"   ‚Ä¢ Successful: {result.get('successful_extractions', 0)}")
                print(f"   ‚Ä¢ Failed: {result.get('failed_extractions', 0)}")
                
                # Database results  
                db_success = result.get('database_success', 0)
                db_failed = result.get('database_failed', 0)
                print(f"üíæ Database Storage: {db_success} success, {db_failed} failed")
                
                # Email results
                email_result = result.get('email_result', {})
                if email_result.get('status') == 'success':
                    print("üì¨ Email A2A: ‚úÖ Success") 
                    if email_result.get('subject'):
                        print(f"   Subject: {email_result['subject']}")
                    if email_result.get('recipient'):
                        print(f"   Recipient: {email_result['recipient']}")
                else:
                    print("üì¨ Email A2A: ‚ùå Failed")
                    if email_result.get('error'):
                        print(f"   Error: {email_result['error']}")
                
                # Show extracted URLs
                print(f"\nüìã Extracted URLs:")
                for i, extraction in enumerate(result.get('extracted_data', []), 1):
                    status_icon = "‚úÖ" if extraction.get('status') == 'success' else "‚ö†Ô∏è" if extraction.get('status') == 'fallback' else "‚ùå"
                    print(f"   {i}. {status_icon} {extraction.get('name', 'Unknown')}")
                    print(f"      URL: {extraction.get('url', 'Unknown')}")
                    print(f"      Type: {extraction.get('extraction_type', 'Unknown')}")
                    
            else:
                print("‚ùå Workflow failed")
                if result.get('error'):
                    print(f"   Error: {result['error']}")
                
            print("=" * 80)
            print("üéâ ENHANCED MCP SYSTEM DEMONSTRATION COMPLETE!")
            print(f"üìß Check your email: {os.getenv('EMAIL_RECIPIENT', 'Not configured')}")
            print("üìÅ Email logs saved to: data/sent_emails.log")
            print("=" * 80)
            
            # Keep system running
            print("\n‚è≥ Keeping system running for 30 seconds...")
            try:
                await asyncio.sleep(30)
            except KeyboardInterrupt:
                print("\n‚èπÔ∏è  System stopped by user")
                
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è  System stopped by user")
        except Exception as e:
            print(f"‚ùå System error: {e}")
        finally:
            self.cleanup()

def main():
    """Main function"""
    # Setup signal handler for cleanup
    def signal_handler(signum, frame):
        print("\n‚èπÔ∏è  Received interrupt signal")
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    
    manager = EnhancedMCPSystemManager()
    
    try:
        asyncio.run(manager.run_enhanced_system())
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  System stopped")
    finally:
        manager.cleanup()

if __name__ == "__main__":
    main()
